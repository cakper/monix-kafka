kafka {
  bootstrap.servers = "localhost:9092"
  client.id = ""

  # E.g. "org.apache.kafka.clients.producer.internals.DefaultPartitioner"
  partitioner.class = null

  acks = "1"
  buffer.memory = 33554432
  compression.type = "none"
  retries = 0
  max.in.flight.requests.per.connection = 5

  ssl.key.password = null
  ssl.keystore.password = null
  ssl.keystore.location = null
  ssl.truststore.password = null
  ssl.truststore.location = null

  batch.size = 16384
  connections.max.idle.ms = 540000
  linger.ms = 0
  max.block.ms = 60000
  max.request.size = 1048576

  receive.buffer.bytes = 65536
  request.timeout.ms = 30000

  sasl.client.callback.handler.class = null
  sasl.jaas.config = null
  sasl.kerberos.service.name = null
  sasl.login.callback.handler.class = null
  sasl.login.class = null
  sasl.mechanism = "GSSAPI"

  security.protocol = "PLAINTEXT"
  send.buffer.bytes = 131072
  ssl.enabled.protocols = "TLSv1.2,TLSv1.1,TLSv1"
  ssl.keystore.type = "JKS"
  ssl.protocol = "TLS"
  ssl.provider = null
  ssl.truststore.type = "JKS"

  enable.idempotence = false

  interceptor.classes = ""

  metadata.max.age.ms = 300000

  metric.reporters = ""
  metrics.num.samples = 2
  metrics.recording.level = "INFO"
  metrics.sample.window.ms = 30000

  reconnect.backoff.max.ms = 1000
  reconnect.backoff.ms = 50

  retry.backoff.ms = 100

  sasl.kerberos.kinit.cmd = "/usr/bin/kinit"
  sasl.kerberos.min.time.before.relogin = 60000
  sasl.kerberos.ticket.renew.jitter = 0.05
  sasl.kerberos.ticket.renew.window.factor = 0.8
  sasl.login.refresh.buffer.seconds = 300
  sasl.login.refresh.min.period.seconds = 60
  sasl.login.refresh.window.factor = 0.8
  sasl.login.refresh.window.jitter =	0.05

  ssl.cipher.suites = null
  ssl.endpoint.identification.algorithm = "https"
  ssl.keymanager.algorithm = "SunX509"
  ssl.secure.random.implementation = null
  ssl.trustmanager.algorithm = "PKIX"

  transaction.timeout.ms = 60000
  transactional.id = null

  # Consumer specific settings

  fetch.min.bytes = 1
  group.id = ""
  heartbeat.interval.ms = 3000
  max.partition.fetch.bytes = 1048576
  auto.offset.reset = "latest"
  enable.auto.commit = true
  auto.commit.interval.ms = 5000
  exclude.internal.topics = true
  receive.buffer.bytes = 65536
  check.crcs = true
  fetch.max.wait.ms = 500
  # Default values for polling
  # See https://cwiki.apache.org/confluence/display/KAFKA/KIP-62%3A+Allow+consumer+to+send+heartbeats+from+a+background+thread
  session.timeout.ms = 10000
  max.poll.records = 500
  max.poll.interval.ms = 300000

  default.api.timeout.ms = 60000
  fetch.max.bytes = 52428800
  isolation.level = "read_uncommitted"
  partition.assignment.strategy = "org.apache.kafka.clients.consumer.RangeAssignor"

  # Monix specific settings

  # Number of requests that KafkaProducerSink
  # can push in parallel
  monix.producer.sink.parallelism = 100
  # Triggers a seekToEnd when the observable starts
  monix.observable.seekEnd.onStart = false
  # Possible values: sync, async
  monix.observable.commit.type = "sync"
  # Possible values: before-ack, after-ack or no-ack
  monix.observable.commit.order = "after-ack"
}
